# Spark Performance

[**Glosario de Databricks**](https://www.databricks.com/glossary)

## General terms

[Apache Hive](https://www.databricks.com/glossary/apache-hive)
> Apache Hive is open-source data warehouse software designed to read, write, and manage large datasets extracted from the Apache Hadoop Distributed File System (HDFS) , one aspect of a larger Hadoop Ecosystem.

[Apache Spark](https://www.databricks.com/glossary/what-is-apache-spark)
>Apache Spark is an open source analytics engine used for big data workloads. It can handle both batches as well as real-time analytics and data processing workloads. Spark provides native bindings for the Java, Scala, Python, and R programming languages. It allows building applications for machine learning, stream processing, and graph processing. 


https://www.databricks.com/glossary/data-lakehouse

https://www.databricks.com/glossary/data-warehouse

## Specific terms

https://www.databricks.com/glossary/what-is-databricks-runtime

https://www.databricks.com/glossary/catalyst-optimizer

> At the core of Spark SQL is the Catalyst optimizer, which leverages advanced programming language features (e.g. Scalaâ€™s pattern matching and quasi quotes) in a novel way to build an extensible query optimizer. Catalyst is based on functional programming constructs in Scala and designed with these key two purposes:
1. Easily add new optimization techniques and features to Spark SQL
2. Enable external developers to extend the optimizer (e.g. adding data source specific rules, support for new data types, etc.)

https://www.databricks.com/glossary/what-are-dataframes

>A DataFrame is a data structure that organizes data into a 2-dimensional table of rows and columns, much like a spreadsheet. DataFrames are one of the most common data structures used in modern data analytics because they are a flexible and intuitive way of storing and working with data.

